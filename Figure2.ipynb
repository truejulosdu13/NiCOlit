{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dft_descriptors.prepocessing import preprocess\n",
    "from classic_descriptors.featurisation import one_hot_encoding\n",
    "from classic_descriptors.featurisation import process_yield\n",
    "from rdkit import Chem\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 25}\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-set downloaded from 10.1126/science.aar5169\n",
    "df_hte = pd.read_csv(\"BH_HTE_scaled_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scope-like descriptors of maximum increase in mean square error \n",
    "# (ref : fig S23 10.1126/science.aar5169)\n",
    "L_scope_reduced = [\n",
    " 'aryl_halide_.C3_NMR_shift',\n",
    " 'aryl_halide_.H2_electrostatic_charge',\n",
    " 'aryl_halide_V2_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization-like descriptors of maximum increase in mean square error \n",
    "# (ref : fig S23 10.1126/science.aar5169)\n",
    "L_opt_reduced = ['additive_.C3_NMR_shift',\n",
    "         'additive_E_LUMO',\n",
    "         'additive_.O1_electrostatic_charge',\n",
    "         'additive_.C5_electrostatic_charge',\n",
    "         'additive_dipole_moment',\n",
    "         'additive_molecular_volume',\n",
    "         'base_electronegativity',\n",
    "         'additive_E_HOMO',\n",
    "         'additive_V1_intensity',\n",
    "         'additive_.C4_NMR_shift',\n",
    "         'additive_V1_frequency',\n",
    "         'additive_surface_area',\n",
    "         'additive_.C4_electrostatic_charge',\n",
    "         'additive_.C3_electrostatic_charge',\n",
    "         'additive_.N1_electrostatic_charge',\n",
    "         'base_.N1_electrostatic_charge',\n",
    "         'base_E_HOMO',\n",
    "         'base_molecular_weight',\n",
    "         'additive_ovality',\n",
    "         'additive_hardness',\n",
    "         'base_dipole_moment',\n",
    "         'base_molecular_volume',\n",
    "         'base_E_LUMO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for HTE-Buchwald Hartwig  \n",
    "# with projections on scope and optimisation\n",
    "df_hte_sco = df_hte[L_scope_reduced]\n",
    "df_hte_opt = df_hte[L_opt_reduced]\n",
    "X_sco = df_hte_sco.values\n",
    "X_opt = df_hte_opt.values\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_sco)\n",
    "X_sco_pc1 = pca.transform(X_sco)\n",
    "sco_pc1 = np.array([i[0] for i in X_sco_pc1])\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X_opt)\n",
    "X_opt_pc1 = pca2.transform(X_opt)\n",
    "opt_pc1 = np.array([i[1] for i in X_opt_pc1])\n",
    "\n",
    "data_hte = pd.DataFrame(data=opt_pc1.reshape(-1,1), columns=[\"opt\"])\n",
    "data_hte[\"sco\"] = sco_pc1.reshape(-1,1)\n",
    "data_hte[\"yield\"] = df_hte[\"yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoLigand\n"
     ]
    }
   ],
   "source": [
    "from dft_descriptors.featurisation import process_dataframe_dft\n",
    "\n",
    "# load NiCOlit dataset\n",
    "df = pd.read_csv(\"data_csv/Data_test11262021.csv\")\n",
    "\n",
    "# preprocessing and dft-featurization\n",
    "def AL_preprocess(df):\n",
    "    df[\"Lewis Acid\"] = df[\"Lewis Acid\"].fillna('NoLewisAcid')\n",
    "    df[\"Lewis Acid\"] = df[\"Lewis Acid\"].replace('nan', 'NoLewisAcid')\n",
    "    Lewis_Acids_to_drop = ['O=C(O[Cs])O[Cs]', 'Cl[Cs]', \n",
    "                       'O=S(=O)(O[Sc](OS(=O)(=O)C(F)(F)F)OS(=O)(=O)C(F)(F)F)C(F)(F)F', \n",
    "                       'F[Cs]', 'O=P(O[Na])(O[Na])O[Na]', '[Rb+]',\n",
    "                       'CC(C)(C)C(=O)O[Cs]', '[Cs+]', 'CC(=O)O[Cu]OC(C)=O', 'F[Sr]F']\n",
    "    for al in Lewis_Acids_to_drop:\n",
    "        df = df[df[\"Lewis Acid\"] != al]  \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# Creating dataframe for NiCOlit projection on scope and optimisation\n",
    "df_lit = preprocess(df)\n",
    "df_lit = AL_preprocess(df_lit)\n",
    "X, y, DOIs, Mecas, Origin, (v_scope, v_optim) = process_dataframe_dft(df_lit, data_path='data_csv/', dim=True)\n",
    "scope = np.array(v_scope)\n",
    "optim = np.array(v_optim)\n",
    "\n",
    "# the first 134 dimension corresponds to the scope dimension\n",
    "X_sco = X[:, :np.sum(v_scope)]\n",
    "# the other dimension corresponds to the optimization dimension\n",
    "X_opt = X[:, np.sum(v_scope):]\n",
    "\n",
    "\n",
    "# Projection on PCA 1 of scope and optimization\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_sco)\n",
    "X_sco_pc1 = pca.transform(X_sco)\n",
    "sco_pc1 = np.array([i[0] for i in X_sco_pc1])\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X_opt)\n",
    "X_opt_pc1 = pca2.transform(X_opt)\n",
    "opt_pc1 = np.array([i[1] for i in X_opt_pc1])\n",
    "\n",
    "df_lit[\"proj scope\"] = sco_pc1\n",
    "df_lit[\"proj optimisation\"] = opt_pc1\n",
    "df_lit[\"yield\"] = y\n",
    "df_lit[\"data type\"] = Origin\n",
    "\n",
    "# Selecting one publication for the plot\n",
    "doi_num = 13\n",
    "dois = df_lit[\"DOI\"].unique()\n",
    "data_doi = df_lit[df_lit[\"DOI\"] == dois[doi_num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yields distribution\n",
    "from rdkit import Chem\n",
    "import dft_descriptors.featurisation as ft\n",
    "import dft_descriptors.prepocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c3643c1552fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Science 360.6385 (2018): 186-190.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataset downloaded from : https://rxn4chemistry.github.io/rxn_yields/data/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_hte_bh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dreher_and_Doyle_input_data.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load HTE dataset originally published in :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/site/rp/work/projects/DD/Anaconda4AI/anaconda3/envs/torch_env/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'; not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "# Load HTE dataset originally published in :\n",
    "# Ahneman et al. \"Predicting reaction performance in Câ€“N cross-coupling using machine learning.\" \n",
    "# Science 360.6385 (2018): 186-190.\n",
    "# dataset downloaded from : https://rxn4chemistry.github.io/rxn_yields/data/\n",
    "df_hte_bh = pd.read_excel(\"Dreher_and_Doyle_input_data.xlsx\")\n",
    "\n",
    "# Load HTE dataset originally published in :\n",
    "# Sandfort et al. \"A structure-based platform for predicting chemical reactivity.\" \n",
    "# Chem (2020).\n",
    "# dataset downloaded from : https://rxn4chemistry.github.io/rxn_yields/data/\n",
    "df_hte_suz = pd.read_excel(\"aap9112_Data_File_S1.xlsx\")\n",
    "\n",
    "# Load NiCOlit dataset and preprocess\n",
    "df_dataset = pd.read_csv(\"../data_csv/Data_test11262021.csv\")\n",
    "df2 = pp.preprocess(df_dataset)\n",
    "df2 = AL_preprocess(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurization of the NiCOlit dataset\n",
    "X, y, DOIs, mechanisms, origin = ft.process_dataframe_dft(df2, data_path=\"data_csv/\", origin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather yields for all datasets :\n",
    "# BH-HTE dataset\n",
    "y_bh = df_hte_bh[\"Output\"]\n",
    "\n",
    "# Suzuki-HTE dataset\n",
    "y_suz = df_hte_suz[\"Product_Yield_PCT_Area_UV\"]\n",
    "\n",
    "# NiCOlit dataset\n",
    "y_dataset = y\n",
    "\n",
    "# Results of the SciFinder query : \n",
    "yields = [\"<10%\", \"10-29%\", \"30-49%\", \"50-69%\", \"70-79%\", \"80-89%\", \"90-100%\"]\n",
    "yields_lim = [0, 10, 29, 49, 69, 79, 89, 100]\n",
    "yields_count =  [ 25, 78, 243, 569, 419, 436, 433]\n",
    "\n",
    "# Simulation of a yield distribution for the SciFinder query : \n",
    "Y_sciF = [np.random.randint(yields_lim[i], yields_lim[i+1]) for i in range(len(yields_count)) for j in range(yields_count[i])]\n",
    "\n",
    "Y = np.concatenate((np.array(y_dataset), np.array(y_suz), np.array(y_bh), np.array(Y_sciF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Origin = np.concatenate((np.array(origin), np.array([\"HTE Suzuki\" for i in range(len(y_suz))]),\n",
    "                        np.array([\"HTE Buchwald\" for i in range(len(y_bh))]),\n",
    "                       np.array([\"SciFinder query\" for i in range(len(Y_sciF))])))\n",
    "Origin2 = np.concatenate((np.array([\"NiCO-lit\" for i in range(len(y_dataset))]),\n",
    "                          np.array([\"HTE Suzuki\" for i in range(len(y_suz))]),\n",
    "                          np.array([\"HTE Buchwald\" for i in range(len(y_bh))]),\n",
    "                         np.array([\"SciFinder query\" for i in range(len(Y_sciF))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df2 =  pd.DataFrame(zip(Y, Origin2), columns =['Yields', 'Origin'])\n",
    "display_df =  pd.DataFrame(zip(y_dataset, origin, mechanisms), columns =['Yields', 'Origin', 'Mechanism'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10, 10))\n",
    "\n",
    "#ax[0,1] = plt.subplot(211)\n",
    "\n",
    "# FIGURE COMP YIELDS DATASETS\n",
    "sns.violinplot(y=\"Yields\", data=display_df2, x='Origin',  \n",
    "               kind=\"swarm\", cut=0, ax = ax[0,0], \n",
    "               linewidth=1, width=1.2, inner=\"box\") #scale='count')\n",
    "for tick in ax[0,0].get_xticklabels():\n",
    "    tick.set_rotation(0)\n",
    "ax[0,0].set_title(\"Datasets Yield Distribution\")\n",
    "ax[0,0].set_xlabel(\"\")\n",
    "ax[0,0].set_ylabel(\"Yield (\\%)\")\n",
    "ax[0,0].set_xticklabels([\"NiCOLit\", \"HTE \\n Suzuki\", \"HTE B-H\", \"SciFinder\\n Query\"])\n",
    "\n",
    "\n",
    "# FIGURE SCOPE/OPT\n",
    "sns.swarmplot(ax=ax[0,1], y=\"Yields\", data=display_df, x='Origin', color='white', s = 3, \n",
    "              linewidth=0.1, dodge=False, edgecolor='black', \n",
    "             )\n",
    "sns.violinplot(y=\"Yields\", data=display_df, x='Origin',  kind=\"swarm\", cut=0, \n",
    "               ax = ax[0,1], palette='Blues', scale='count',\n",
    "              linewidth=1)\n",
    "ax[0,1].set_title(\"Scope and Optimisation Yield Distribution\\n in the NiCOlit Dataset\")\n",
    "ax[0,1].set_xlabel(\"\")\n",
    "ax[0,1].set_ylabel(\"\")\n",
    "\n",
    "\n",
    "# FIGURE SCOPE/OPT in HTE\n",
    "sns.scatterplot(x='opt', y='sco', hue='yield', data=data_hte, marker=\"s\",\n",
    "                legend=\"auto\", ax = ax[1,0], palette='flare')\n",
    "\n",
    "ax[1,0].set_title(\"B-H HTE Chemical Space Coverage\")\n",
    "ax[1,0].legend(title=\"Yield (\\%)\", loc = 'upper right')\n",
    "ax[1,0].set_xlabel(\"PC 2 of optimisation subspace\")\n",
    "ax[1,0].set_ylabel(\"PC 1 of scope subspace\")\n",
    "ax[1,0].set_xticks([])\n",
    "ax[1,0].set_yticks([])\n",
    "handles0 = ax[1,0].get_legend_handles_labels()\n",
    "\n",
    "# FIGURE SCOPE/OPT in NiCOLit\n",
    "sns.scatterplot(data=data_doi, x='proj scope', y='proj optimisation', \n",
    "                hue='yield', ax = ax[1,1], style=\"data type\", legend=\"auto\",\n",
    "                palette='flare')\n",
    "ax[1,1].set_title(\"Academic Publication Chemical Space Coverage\")\n",
    "ax[1,1].set_xlabel(\"PC 1 of optimisation subspace\")\n",
    "ax[1,1].set_ylabel(\"PC 1 of scope subspace\")\n",
    "ax[1,1].set_xticks([])\n",
    "ax[1,1].set_yticks([])\n",
    "\n",
    "handles = ax[1,1].get_legend_handles_labels()\n",
    "h0 = handles[0] \n",
    "h0.append(handles[0][0])\n",
    "h0.append(handles[0][0])\n",
    "h1 = ['Yield (\\%)', '15', '30', '45', '60', '75', 'data type', 'optimisation', 'scope', '', '']\n",
    "ax[1,1].get_legend().remove()\n",
    "ax[1,1].legend(h0, h1, ncol=2, loc='upper right')\n",
    "\n",
    "plt.savefig('figure2.svg', dpi=600, format='svg',\n",
    "     bbox_inches='tight' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
