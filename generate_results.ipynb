{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import dft_descriptors.prepocessing as pp\n",
    "import dft_descriptors.featurisation as ft\n",
    "from featurisation import process_dataframe\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from analysis import analysis_stratification_influence, analysis_train_set_size, analysis_stratification_influence_substrates, get_raw_results, analysis_stratification_influence_substrates_raw\n",
    "\n",
    "# data sources: data_csv/rxn_dataset, Data_test11222021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('predictor', RandomForestRegressor())]\n",
    "pipe = Pipeline(estimators)\n",
    "metric = r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('data_csv/rxn_dataset.csv')\n",
    "X_rxnfp = np.array([json.loads(x) for x in df_dataset.rxnfp])\n",
    "substrate_rxnfp = np.array(df_dataset.Substrate) \n",
    "DOI_rxnfp = np.array(df_dataset.DOI) \n",
    "mechanisms_rxnfp = np.array(df_dataset.Mechanism) \n",
    "origins_rxnfp = np.array(df_dataset.Origin) \n",
    "y_rxnfp = np.array(df_dataset.Yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = pd.read_csv(\"data_csv/Data_test11222021.csv\", sep = ',')\n",
    "# Removing \n",
    "vc = df_dft.DOI.value_counts()\n",
    "doi_above_10 = np.array(vc[vc > 20].index)\n",
    "\n",
    "indexes = []\n",
    "\n",
    "for i, row in df_dft.iterrows():\n",
    "    if row[\"DOI\"] not in doi_above_10:\n",
    "        indexes.append(i)\n",
    "        \n",
    "df_dft = df_dft.drop(indexes)\n",
    "df_dft = df_dft.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = pp.preprocess(df_dft)\n",
    "df_dft[\"Lewis Acid\"] = df_dft[\"Lewis Acid\"].fillna('NoLewisAcid')\n",
    "df_dft[\"Lewis Acid\"] = df_dft[\"Lewis Acid\"].replace('nan', 'NoLewisAcid')\n",
    "\n",
    "Lewis_Acids_to_drop = ['O=C(O[Cs])O[Cs]', 'Cl[Cs]', \n",
    "                       'O=S(=O)(O[Sc](OS(=O)(=O)C(F)(F)F)OS(=O)(=O)C(F)(F)F)C(F)(F)F', \n",
    "                       'F[Cs]', 'O=P(O[Na])(O[Na])O[Na]', '[Rb+]',\n",
    "                       'CC(C)(C)C(=O)O[Cs]', '[Cs+]', 'CC(=O)O[Cu]OC(C)=O', 'F[Sr]F']\n",
    "for al in Lewis_Acids_to_drop:\n",
    "    df_dft = df_dft[df_dft[\"Lewis Acid\"] != al]\n",
    "    \n",
    "df_dft = df_dft.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_kept_dft = np.array(df_dft.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoLigand\n"
     ]
    }
   ],
   "source": [
    "X_dft, y_dft, DOI_dft, mechanisms_dft, origins_dft = ft.process_dataframe_dft(df_dft, data_path=\"data_csv/\", origin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoLigand\n"
     ]
    }
   ],
   "source": [
    "X_hybrid, y_hybrid, DOI_hybrid, mechanisms_hybrid, origins_hybrid = ft.process_dataframe_dft(df_dft, data_path=\"data_csv/\", origin=False, hybrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = pd.read_csv('data_csv/Data_test11222021.csv')\n",
    "df_fp = pp.preprocess(df_fp)\n",
    "vc = df_fp.DOI.value_counts()\n",
    "doi_above_10 = np.array(vc[vc > 20].index)\n",
    "\n",
    "indexes = []\n",
    "\n",
    "for i, row in df_fp.iterrows():\n",
    "    if row[\"DOI\"] not in doi_above_10:\n",
    "        indexes.append(i)\n",
    "        \n",
    "df_fp = df_fp.drop(indexes)\n",
    "df_fp = df_fp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fp, y_fp, DOI_fp, mechanisms_fp, origins_fp = process_dataframe(df_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_fp, y_fp, origins_fp, mechanisms_fp, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_fp_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_fp[indexes_kept_dft, :], y_fp[indexes_kept_dft], DOI_fp[indexes_kept_dft], metric=metric, predictor=pipe, n_iterations_external=5, n_iterations_internal=5)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"results/training_size_influence_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_dft, y_dft, origins_dft, mechanisms_dft, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_dft_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_dft, y_dft, DOI_dft, metric=metric, predictor=pipe, n_iterations_external=5, n_iterations_internal=5)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"results/training_size_influence_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_rxnfp, y_rxnfp, origins_rxnfp, mechanisms_rxnfp, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_rxnfp_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_rxnfp[indexes_kept_dft, :], y_rxnfp[indexes_kept_dft], DOI_rxnfp[indexes_kept_dft], metric=metric, predictor=pipe, n_iterations_external=5, n_iterations_internal=5)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"results/training_size_influence_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substrate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_fp, y_fp, list(df_fp[\"Reactant Smile (C-O)\"]), origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/substrate_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_dft, 1 * y_dft>50, list(df_dft[\"Reactant Smile (C-O)\"]), origins_dft , metric=metric, predictor=RandomForestClassifier(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/substrate_split_dft_descriptors_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_fp, y_fp, list(df_fp[\"Reactant Smile (C-O)\"]), origins_fp, metric=metric, predictor=KNeighborsRegressor(n_neighbors=1), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/substrate_split_fp_descriptors_KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_rxnfp, y_rxnfp, substrate_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/substrate_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOI split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_fp, y_fp, DOI_fp, origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/doi_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_dft, y_dft, DOI_dft, origins_dft , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/doi_split_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_rxnfp, y_rxnfp, DOI_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/doi_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanism split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_fp, y_fp, mechanisms_fp, origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/mechanisms_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_dft, y_dft, mechanisms_dft, origins_dft , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/mechanisms_split_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratification_results, additional_stratification_results, global_results, global_baseline_results, values = analysis_stratification_influence_substrates_raw(X_rxnfp, y_rxnfp, mechanisms_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Global model', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"results/mechanisms_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted chemical space: Suzuki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(mechanisms_fp=='Suzuki')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_fp[indexes, :], y_fp[indexes], origins_fp[indexes], mechanisms_fp[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_fp_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(mechanisms_dft=='Suzuki')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_dft[indexes, :], y_dft[indexes], origins_dft[indexes], mechanisms_dft[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_dft_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(mechanisms_rxnfp=='Suzuki')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_rxnfp[indexes, :], y_rxnfp[indexes], origins_rxnfp[indexes], mechanisms_rxnfp[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_rxnfp_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al _coupling\n",
      "0.16\n",
      "Buchwald\n",
      "-0.17\n",
      "C-H activation\n",
      "0.49\n",
      "CO2 Insertion\n",
      "0.49\n",
      "Isocyanates\n",
      "0.25\n",
      "Kumada\n",
      "0.51\n",
      "Murahashi\n",
      "-0.11\n",
      "Negishi\n",
      "0.64\n",
      "Ni/Cu cooperation\n",
      "0.71\n",
      "P_coupling\n",
      "-0.12\n",
      "Suzuki\n",
      "0.38\n"
     ]
    }
   ],
   "source": [
    "# TODO: clean \n",
    "r2 = []\n",
    "length = []\n",
    "for mecha in np.unique(mechanisms_dft):\n",
    "    indexes = np.where(mechanisms_dft==mecha)[0]\n",
    "    values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_dft[indexes, :], y_dft[indexes], origins_dft[indexes], mechanisms_dft[indexes], n_iterations=10)\n",
    "    print(mecha)\n",
    "    print(round(r2_score(values, model_values), 2))\n",
    "    r2.append(round(r2_score(values, model_values), 2))\n",
    "    length.append(len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al _coupling\n",
      "0.08972712181077747\n",
      "Buchwald\n",
      "0.08334623783177508\n",
      "C-H activation\n",
      "0.5352837823528319\n",
      "CO2 Insertion\n",
      "0.4633179584210968\n",
      "Isocyanates\n",
      "0.38676919690169564\n",
      "Kumada\n",
      "0.48824921796229437\n",
      "Murahashi\n",
      "-0.0450133373194348\n",
      "Negishi\n",
      "0.5230062567743744\n",
      "Ni/Cu cooperation\n",
      "0.6848397251089264\n",
      "P_coupling\n",
      "0.43813325210992704\n",
      "Suzuki\n",
      "0.44687822151557066\n"
     ]
    }
   ],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_dft, y_dft, origins_dft, mechanisms_dft, n_iterations=10)\n",
    "for mecha in np.unique(mechanisms_dft):\n",
    "    indexes = np.where(np.array(additional_stratification_values)==mecha)[0]\n",
    "    print(mecha)\n",
    "    print(round(r2_score(np.array(values)[indexes], np.array(model_values)[indexes])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted chemical space: publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(DOI_fp=='https://doi.org/10.1021/ja8056503')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_fp[indexes, :], y_fp[indexes], origins_fp[indexes], mechanisms_fp[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_fp_descriptors_test_size_0.2_publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(DOI_dft=='https://doi.org/10.1021/ja8056503')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_dft[indexes, :], y_dft[indexes], origins_dft[indexes], mechanisms_dft[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_dft_descriptors_test_size_0.2_publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(DOI_rxnfp=='https://doi.org/10.1021/ja8056503')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = get_raw_results(X_rxnfp[indexes, :], y_rxnfp[indexes], origins_rxnfp[indexes], mechanisms_rxnfp[indexes], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Global model', 'Origin', 'Mechanism'])\n",
    "display_df.to_csv(\"results/random_split_rxnfp_descriptors_test_size_0.2_publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
