{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import descriptors.preprocessing as pp\n",
    "import descriptors.dft_featurisation as dft_ft\n",
    "import descriptors.rdkit_featurisation as rdkit_ft\n",
    "from analysis import analysis_train_set_size, random_split, stratified_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('predictor', RandomForestRegressor())]\n",
    "pipe = Pipeline(estimators)\n",
    "metric = r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = pd.read_csv(\"../data/NiCOlit.csv\", sep = ',')\n",
    "df_dft, indexes = pp.preprocess(df_dft)\n",
    "indexes_dft = []\n",
    "for idx in df_dft.index:\n",
    "    indexes_dft.append(idx)\n",
    "df_dft = df_dft.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('../data/rxnfp_featurization/rxn_dataset_2.csv')\n",
    "df_dataset = df_dataset.loc[indexes_dft]\n",
    "df_dataset = df_dataset.reset_index(drop=True)\n",
    "X_rxnfp = np.array([json.loads(x) for x in df_dataset.rxnfp])\n",
    "substrate_rxnfp = np.array(df_dataset.Substrate) \n",
    "DOI_rxnfp = np.array(df_dataset.DOI) \n",
    "mechanisms_rxnfp = np.array(df_dataset[\"A-X type\"]) \n",
    "origins_rxnfp = np.array(df_dataset.Origin) \n",
    "y_rxnfp = np.array(df_dataset.Yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dft, y_dft, DOI_dft, mechanisms_dft, origins_dft, substrate_dft, ligand_dft = dft_ft.process_dataframe_dft(df_dft, data_path=\"../data/utils/\", origin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = pd.read_csv('../data/NiCOlit.csv')\n",
    "df_fp, indexes = pp.preprocess(df_fp)\n",
    "df_fp = df_fp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fp, y_fp, DOI_fp, mechanisms_fp, origins_fp = rdkit_ft.process_dataframe(df_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_fp, y_fp, origins_fp, mechanisms_fp, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), \n",
    "                           columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_fp_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "#metric_values, baseline_values, sizes = analysis_train_set_size(X_fp[indexes_kept_dft, :], y_fp[indexes_kept_dft], DOI_fp[indexes_kept_dft], metric=metric, predictor=pipe, \n",
    "#                                                                n_iterations_external=10, n_iterations_internal=1)\n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_fp, y_fp, DOI_fp, metric=metric, predictor=pipe, \n",
    "                                                                n_iterations_external=10, n_iterations_internal=1)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"../results/training_size_influence_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft, y_dft, origins_dft, mechanisms_dft, \n",
    "                                                                                                              n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_dft_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_dft, y_dft, DOI_dft, metric=metric, predictor=pipe,\n",
    "                                                                n_iterations_external=10, n_iterations_internal=1)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"../results/training_size_influence_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(origins_dft == \"Scope\")[0]\n",
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft[indices, :], y_dft[indices], origins_dft[indices], mechanisms_dft[indices], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_dft_descriptors_scope_test_size_0.2\")\n",
    "\n",
    "indices = np.where(origins_dft == \"Optimisation\")[0]\n",
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft[indices, :], y_dft[indices], origins_dft[indices], mechanisms_dft[indices], n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_dft_descriptors_optimisation_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_rxnfp, y_rxnfp, origins_rxnfp, mechanisms_rxnfp, n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_rxnfp_descriptors_test_size_0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size influence \n",
    "metric_values, baseline_values, sizes = analysis_train_set_size(X_rxnfp, y_rxnfp, DOI_rxnfp, metric=metric, predictor=pipe,\n",
    "                                                                n_iterations_external=10, n_iterations_internal=1)\n",
    "metric_mean = np.mean(metric_values, axis=1)\n",
    "metric_lower = np.percentile(metric_values, 5, axis=1)\n",
    "metric_upper = np.percentile(metric_values, 95, axis=1)\n",
    "\n",
    "baseline_mean = np.mean(baseline_values, axis=1)\n",
    "baseline_lower = np.percentile(baseline_values, 5, axis=1)\n",
    "baseline_upper = np.percentile(baseline_values, 95, axis=1)\n",
    "\n",
    "display_df =  pd.DataFrame(zip(metric_mean, metric_lower, metric_upper, baseline_mean, baseline_lower, baseline_upper, sizes), columns = ['Metric mean', 'Metric lower','Metric upper','Baseline mean', 'Baseline lower','Baseline upper', 'Sizes'])\n",
    "display_df.to_csv(\"../results/training_size_influence_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substrate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_fp, y_fp, list(df_fp[\"substrate\"]), origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/substrate_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_dft, 1 * y_dft>50, list(df_dft[\"substrate\"]), origins_dft , metric=metric, predictor=RandomForestClassifier(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/substrate_split_dft_descriptors_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_fp, y_fp, list(df_fp[\"substrate\"]), origins_fp, metric=metric, predictor=KNeighborsRegressor(n_neighbors=1), test_size=0.2, \n",
    "                                                                                                                              n_iterations=2)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/substrate_split_fp_descriptors_KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_rxnfp, y_rxnfp, substrate_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2,\n",
    "                                                                                                                              n_iterations=2)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/substrate_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOI split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_fp, y_fp, DOI_fp, origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/doi_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_dft, y_dft, DOI_dft, origins_dft , metric=metric, predictor=RandomForestRegressor(), test_size=0.2,\n",
    "                                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/doi_split_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_rxnfp, y_rxnfp, DOI_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/doi_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coupling partner split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_fp, y_fp, mechanisms_fp, origins_fp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/mechanisms_split_fp_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_dft, y_dft, mechanisms_dft, origins_dft , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=10)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/mechanisms_split_dft_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, global_baseline_results, global_results, stratification_results, additional_stratification_results = stratified_split(X_rxnfp, y_rxnfp, mechanisms_rxnfp, origins_rxnfp , metric=metric, predictor=RandomForestRegressor(), test_size=0.2, \n",
    "                                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(stratification_results, additional_stratification_results, global_results, global_baseline_results, values), columns =['Substrate', 'Origin', 'Predicted Yields', 'Global baseline', 'Yields'])\n",
    "display_df.to_csv(\"../results/mechanisms_split_rxnfp_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted chemical space: Suzuki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(mechanisms_fp=='B')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_fp[indexes, :], y_fp[indexes], origins_fp[indexes], mechanisms_fp[indexes], \n",
    "                                                                                                              n_iterations=5)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_fp_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(mechanisms_dft=='B')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft[indexes, :], y_dft[indexes], origins_dft[indexes], mechanisms_dft[indexes], \n",
    "                                                                                                              n_iterations=1)\n",
    "display_df = pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_dft_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_rxnfp[indexes, :], y_rxnfp[indexes], origins_rxnfp[indexes], mechanisms_rxnfp[indexes], \n",
    "                                                                                                              n_iterations=1)\n",
    "display_df =  pd.DataFrame(zip(values, baseline_values, model_values, stratification_values, additional_stratification_values), columns = ['Yields', 'Baseline', 'Predicted Yields', 'Origin', 'Coupling Partner'])\n",
    "display_df.to_csv(\"../results/random_split_rxnfp_descriptors_test_size_0.2_mechanism_suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al\n",
      "53\n",
      "0.158\n",
      "B\n",
      "472\n",
      "0.433\n",
      "C-H\n",
      "271\n",
      "0.584\n",
      "CO2\n",
      "87\n",
      "0.482\n",
      "Li\n",
      "52\n",
      "-0.133\n",
      "NCO\n",
      "57\n",
      "0.265\n",
      "NH\n",
      "27\n",
      "-0.165\n",
      "RMgX\n",
      "266\n",
      "0.507\n",
      "Si\n",
      "53\n",
      "0.437\n",
      "Zn\n",
      "68\n",
      "0.645\n"
     ]
    }
   ],
   "source": [
    "# TODO: clean \n",
    "r2 = []\n",
    "length = []\n",
    "for mecha in np.unique(mechanisms_dft):\n",
    "    indexes = np.where(mechanisms_dft==mecha)[0]\n",
    "    values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft[indexes, :], y_dft[indexes], origins_dft[indexes], mechanisms_dft[indexes], n_iterations=10)\n",
    "    print(mecha)\n",
    "    print(len(indexes))\n",
    "    print(round(r2_score(values, model_values), 3))\n",
    "    r2.append(round(r2_score(values, model_values), 3))\n",
    "    length.append(len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al\n",
      "0.2\n",
      "B\n",
      "0.467\n",
      "C-H\n",
      "0.587\n",
      "CO2\n",
      "0.518\n",
      "Li\n",
      "-0.105\n",
      "NCO\n",
      "0.402\n",
      "NH\n",
      "0.171\n",
      "RMgX\n",
      "0.503\n",
      "Si\n",
      "0.636\n",
      "Zn\n",
      "0.553\n"
     ]
    }
   ],
   "source": [
    "values, baseline_values, model_values, stratification_values, additional_stratification_values = random_split(X_dft, y_dft, origins_dft, mechanisms_dft, n_iterations=50)\n",
    "for mecha in np.unique(mechanisms_dft):\n",
    "    indexes = np.where(np.array(additional_stratification_values)==mecha)[0]\n",
    "    print(mecha)\n",
    "    print(round(r2_score(np.array(values)[indexes], np.array(model_values)[indexes]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A-X type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/envs/dft_for_sm/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dft_for_sm/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dft_for_sm/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A-X type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c8/7pbzw0r912n01vr9fgdmzhx00000gn/T/ipykernel_99011/2328662432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0max_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_dft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A-X type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_dft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A-X type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0max_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DOI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dft_for_sm/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dft_for_sm/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A-X type'"
     ]
    }
   ],
   "source": [
    "for ax_t in df_dft[\"A-X type\"].unique():\n",
    "    print(ax_t)\n",
    "    print(len(df_dft[df_dft[\"A-X type\"]==ax_t][\"DOI\"].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
